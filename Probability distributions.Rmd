---
title: 'Probability Distributions'
author: "Shenghao Wu"
date: "March 25, 2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(ggplot2)
```

## The Geometric Probability Distribution & Weak Law of Large Numbers

Let us roll a $K$ sided die with numbers $1$, . . . , $K$ written on them where $K > 1$.  Each number is equally likely to be rolled.  Let $X$ be a random variable representing the number of rolls needed to get the number $K$ for the first time.  (Note:  number of rolls includes the roll where $K$ appears.)

1. On any roll, what is the probability of rolling the value $K$?


```{r}
# 1/k
```


2. What are all of the possible values of $X$?
1<=$x$<+âˆž

3. Create a function with arguments, ```K``` and ```n_sims```, with ```n_sims``` representing the number of times we should play out this scenario.  Your function should return the number of times the die was rolled in order to get the value ```K```.  (Helpful hint: Try using a while loop)

```{r}
# Through function we can get how many times we need to get k
nfact <- function(k){
  x<-0
  t<-0
  while(x!=k)
  {
  x<-sample(x = 1:k, size = 1, replace = FALSE)
  t<-t+1
  }
  return(t)
}
# Then through nfact2 we can get how many times we need to get the value k 
nfact2 <- function(k,n_sims){
  
  nfact <- function(k){
  x<-0
  t<-0
  while(x!=k)
  {
  x<-sample(x = 1:k, size = 1, replace = FALSE)
  t<-t+1
  }
  return(t)
  
}
  q<-replicate(n_sims,nfact(k))
  return(q)
}
nfact2(12,5)
```


4.  For $K = [2, 6, 12, 15]$ simulate 100 rounds of the scenario and plot each set of results with a bar graph.

```{r}
#k=2,6,12,15  k_sim=100
nfact2(2,100)
nfact2(6,100)
nfact2(12,100)
nfact2(15,100)
table(nfact2(15,100))
par(mfrow=c(2,4))
plot(table(nfact2(2,100)),xlab = 'Number of k', ylab = 'Frequency', main = 'k=2 and 100 times scenario')
plot(table(nfact2(6,100)),xlab = 'Number of k', ylab = 'Frequency', main = 'k=6 and 100 times scenario')
plot(table(nfact2(12,100)),xlab = 'Number of k', ylab = 'Frequency', main = 'k=12 and 100 times scenario')
plot(table(nfact2(15,100)),xlab = 'Number of k', ylab = 'Frequency', main = 'k=15 and 100 times scenario')
```


5.  Repeat question 4 by simulating 100 new rounds of each scenario and plot the results.  Have your results changed?  Please explain how they have changed.  Why might your results be different?

```{r}
# Here are some difference, if we have more trails, the graph is more similiar to a ladder
plot(table(nfact2(2,200)),xlab = 'Number of k', ylab = 'Frequency', main = 'k=2 and 200 times scenario')
plot(table(nfact2(6,200)),xlab = 'Number of k', ylab = 'Frequency', main = 'k=6 and 200 times scenario')
plot(table(nfact2(12,200)),xlab = 'Number of k', ylab = 'Frequency', main = 'k=12 and 200 times scenario')
plot(table(nfact2(15,200)),xlab = 'Number of k', ylab = 'Frequency', main = 'k=15 and 200 times scenario')

```


6.  For each combination of ```n_sim`` = [100, 1000, 10000, 100000] and $K$ = [2, 6, 12, 15] calculate the average number of rolls required to get $K$.  Show these results in a table where your columns are values of n_sim and your rows are values of $K$.

```{r}

m<-c(mean(nfact2(2,100)),
mean(nfact2(6,100)),
mean(nfact2(12,100)),
mean(nfact2(15,100)),
mean(nfact2(2,1000)),
mean(nfact2(6,1000)),
mean(nfact2(12,1000)),
mean(nfact2(15,1000)),
mean(nfact2(2,10000)),
mean(nfact2(6,10000)),
mean(nfact2(12,10000)),
mean(nfact2(15,10000)),
mean(nfact2(2,100000)),
mean(nfact2(6,100000)),
mean(nfact2(12,100000)),
mean(nfact2(15,100000)))
m
mmatrix<-matrix(m,byrow=TRUE,nrow=4)
mmatrix
mt<-as.table(mmatrix)
mt
colnames(mt) = c("nsim=100","nsim=1000","nsim=10000","nsim=100000")
rownames(mt) = c("K=2","K=6","K=12","K=15")
# The table is mt
mt

```


7.  How would you describe a general formula for calculating the average number of rolls?
mean(nfact2(k,n_sim))

8.  For $K$ = 6 and ```n_sim``` = 1000, estimate the following probabilities using your simulation function:

```{r}
dataset<-nfact2(6,1000)
table(dataset)

#X=1 p=0.169
169/1000
#x=2 p=0.132
132/1000
#x=3 p=0.112
112/1000
#x=4 p=0.091
91/1000
#x=5 p=0.090
90/1000
#x=6 p=0.069
69/1000
sum(49,52,43,31,32,19,14,18,11,10,6,9,7,5,3,6,4,3,1,2,2,3,1,1,1,1,1,1)/1000
#x>=7 p=0.336
```


9.  In theory, is the probability $P(X = 500)$ > 0 when $K$ = 6?  Explain.

Yes, in theory any number of x is possible, die may be keep rooled to any number except 6 for 499 times. 

10.  Given that the probability mass function for the a geometric distributed random variable $X$ is  $$P(X = x) = P( \overbrace{Fail, Fail,...,Fail}^{x-1}, Success) = qq...qp= q^{x-1}p$$ Use the functions ```dgeom()``` and ```pgeom()``` to calculate the probabilites in question 8.  For the ```x``` arguments, enter the outcomes ```x-1``` and your answer for #1 for the argument prob.  (Hint: Check ?dgeom if you need help)

```{r}

# This is the theoretical probability for P(X=x) where x={1,...6}
theo6 <- dgeom((1:6)-1,1/6)
theo6
theo10<- dgeom((1:10)-1,1/6)
theo10
# This is the theoretical probability for P(X>=7) 
theo7plus <- pgeom(5, 1/6, lower.tail=FALSE)
theo7plus


```


11.  Create a figure with two plots side by side: The first plot of the empirical probability mass function estimate based on the data simulated in #8 (histogram is acceptable - use ```prob=TRUE```).  The second plot should plot the theorical probability mass function for our data in #10.

```{r}

par(mfrow = c(1,2))
table(dataset)

plot1<-hist(dataset,xlim=c(0,50),ylim=c(0,0.2),breaks=(0:50),main="Histogram of question8",col='red',xlab="X",ylab="Empirical probability",prob=TRUE)

trytimesx<-c(1,2,3,4,5,6,7,8,9,10)
probx<-c(0.16666667,0.13888889,0.11574074,0.09645062,0.08037551,0.06697960,0.05581633,0.04651361,0.03876134,0.03230112)
dataq10<- data.frame(trytimesx,probx)
dataq10
barplot(height=dataq10$probx,names=dataq10$trytimesx,
        col="red",xlab="x",cex.lab=2,ylim=c(0,0.2),main="Histogram of question10")







```


12.  How close are your answers from your simulation to the probabilities from the geometric distribution you just created?  Describe this given what we've learned about the Weak Law of Large Numbers in lecture 8.  What parameters need to change in our function in order for our empirical probabilities to match the theoretical values for $(X=x)$

```{r}
#I think very close,we just need to increase the number of trials to make our empirical probabilities to match the theretical values.maybe increase 1000 in Q8 to 100000

```


13.  For $K$ = 6, and ```n_sim``` = [1 - 5000] (Hint: use a for loop) plot the mean of each sample as a line graph.  Add a horizontal line at the theorical mean (6).  What is your observation of this relationship between n_sim and the mean of our sample?  

```{r}
n=c(1:500)
m<-c()
for (val in n){
  n<-nfact2(6,val)
  m<-c(m,mean(n))
}
m

t=1:500
plot(t,m,type="l",xlab="n_sim",ylab="mean of each sample",main="Mean of 5000 sample")
abline(h=6,col="red")

# My obeservation is with n_sim keep increasing, the mean of each sample becomes closer to 6
```



14.  For $K$ = 6, what is the probability that it takes more than 12 rolls to roll a 6?

```{r}
#11.2156%
pgeom(q = 11, prob = 1/6, lower.tail = FALSE)
```


15.  For $K$ = 6, what is the probability that you roll a 6 in your first three rolls?

```{r}
#42.12963%
pgeom(q=2,prob=1/6,lower.tail=TRUE)
```


16.  For $K$ = 6, what is the 95th percentile for number of rolls required to roll a 6?

```{r}
qgeom(0.95,1/6)
#16 failures, so 17 rolls would be the 95th percentile for number of rolls required to roll 6.  
```


## The Exponential Probability Distribution & Central Limit Theorem

The magnitude of earthquakes in North America can be modeled as having an exponential distribution with mean $\mu$ of 2.4.

For an _exponential distribution_:

**Mean:** $\mathbb{E}[X] = {\lambda}$

**Variance:** $\mathbb{E}[X^2] - (\mathbb{E}[X])^2 = \lambda^2$

18. Simulate 1000 earthquakes and plot the distribution of Richter Scale values (Hint: ```rexp(x, rate = 1/lambda)```).  Let this data represent $X$. Create a histogram of $X$ and describe the shape of this distribution.  How does this differ from the normal distribution?

```{r}
1/2.4
x<-rexp(1000,1/2.4)
hist(x)

#Normal distribution is symmetic but exponential distribution is not
```


19.  Find the probability that an earthquake occurring in North America will fall between 2 and 4 on the Richter Scale.

```{r}
sum(2<x & x<4)
256/1000
#The probability will be 0.256
```


20.  How rare is an earthquake with a Richter Scale value of greater than 9?

```{r}
sum(x>9)
#The likelihood is as low as 0.023
```


21.  Create a function which will simulate multiple samples drawn from an exponential distribution with $\lambda$ = 2.4 (Hint: ```rexp(x, rate = 1/lambda)``` and return a vector containing the mean values for each of your samples.  Your arguments should be lamba, n_sims for the number of simulations per sample, and n_samples for the number of samples of size n_sims to be created.  

```{r}

funk21<-function(lambda,n_sim,n_samples){
  k=0
  mea<-c()
  while(k!=n_samples)
  {
    k=k+1
    y<-mean(rexp(n_sim,1/lambda))
    mea<-c(mea,y)
  }
  return(mea)
}
```


22.  Use your function with arguments ```lambda``` = 2.4, ```n_sim``` = 1000, ```n_samples``` = 40 to create a vector of mean values of Richter Scale readings.  Let $\bar{X}$ represent this data.  Plot a histogram of the data.  Describe the distribution of $\bar{X}$.  Is $\bar{X}$ distributed differently than $X$?

```{r}
#m22 is xbar
m22<-funk21(2.4,1000,40)
hist(m22)
#They look different, barx seems like normal distribution
```

23.  Calculate the sample mean and sample variance for the data simulated in #18.  Calculate the population variance given $\lambda$ = 2.4.

```{r}
mean(x)

var(x)
2.4^2

```


24.  Create a plot of $\bar{X}$.  Make sure to set ```prob=TRUE``` in the ```hist()``` function.  Include vertical lines for the sample and theoretical mean values (red = sample mean, blue = theoretical mean).


```{r}
mean(m22)

xbarplot<-hist(m22,prob=TRUEï¼Œmain="Density of Xbar",xlab="Xbar")
abline(v=2.3917,col="red")
abline(v=2.4,col="blue")

```


25.  Add lines to our plot of $\bar{X}$ to plot the density for both our simulated sample and theoretical population (Hint: use ```dnorm(x, mean=lambda, sd=(lambda/sqrt(n_samples))``` to calculate theorical population density).  Make sure to set ```prob=TRUE``` in the ```hist()``` function. 

```{r}
# Add theoretical normal distribution for mean
m22<-funk21(2.4,1000,40)
xbarplot<-hist(m22,prob=TRUEï¼Œmain="Density of Xbar",xlab="Xbar")
curve(dnorm(x, mean = 2.4, sd = 2.4/sqrt(1000)), from = min(m22), to = max(m22), add = TRUE, col = "green")
lines(density(m22), col = "royalblue", lwd=2)

```


26.  The Central Limit Theorem states that if you take many repeated samples from a population, and calculate the averages or sum of each one, the collection of those averages will be normally distributed. Does the shape of the distribution of $X$ matter with respect to the distribution of $\bar{X}$?  Is this true for all **any** parent distribution of $\bar{X}$?

It looks like they are not matter with each other


27.  What will happen to the distribution of $\bar{X}$ if you re-run your function with arguments ```lambda``` = 2.4, ```n_sim``` = 10000, ```n_samples``` = 40?  How does the variance of $\bar{X}$ change from our data simulated for $\bar{X}$ in #25?  Create a figure with the histograms (```prob=TRUE```) for both of our $\bar{X}$ sampling distributions.  Explain the difference in the two distributions of $\bar{X}$

```{r}
xbarplot<-hist(m22,prob=TRUEï¼Œmain="Density of Xbar",xlab="Xbar")
m27<-funk21(2.4,10000,40)
xbarplot<-hist(m27,prob=TRUEï¼Œmain="Density of Xbar",xlab="Xbar")
#There is no any significant change because n_samples didn't change
```



